{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"J'aime programmer.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 19, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_ee1d74bde0', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-5ca3c9d9-02fc-42f5-b5ad-6e2a63612814-0' usage_metadata={'input_tokens': 19, 'output_tokens': 5, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import requests\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_chat_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "\n",
    "# Initialize the Azure OpenAI model\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=openai_api_version,\n",
    "    azure_deployment=azure_chat_deployment,\n",
    ")\n",
    "\n",
    "# Create a human message and invoke the model\n",
    "message = HumanMessage(\n",
    "    content=\"Translate this sentence from English to French. I love programming.\"\n",
    ")\n",
    "response = model.invoke([message])\n",
    "\n",
    "# Print the response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    api_key = openai_api_key,\n",
    "    azure_deployment=\"text-embedding-3-large\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import random\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Product data\n",
    "# ----------------------------\n",
    "data = {\n",
    "    \"Product ID\": [f\"P{str(i).zfill(3)}\" for i in range(1, 31)],\n",
    "    \"Product Name\": [\n",
    "        \"Classic Piadina\", \"Vegetarian Piadina\", \"Ham & Cheese Piadina\", \n",
    "        \"Nutella Piadina\", \"Caprese Salad\", \"Tigelle Bread\", \n",
    "        \"Sun-Dried Tomatoes\", \"Parmesan Cheese\", \"Prosciutto Crudo\", \n",
    "        \"Balsamic Vinegar\", \"Truffle Piadina\", \"Spicy Salami Piadina\", \n",
    "        \"Vegan Piadina\", \"Chicken Caesar Salad\", \"Garlic Bread\", \n",
    "        \"Olive Tapenade\", \"Ricotta Cheese\", \"Mortadella\", \n",
    "        \"Pesto Sauce\", \"Marinated Artichokes\", \"Four Cheese Piadina\", \n",
    "        \"Grilled Eggplant\", \"Smoked Salmon Piadina\", \"Tuna Salad\", \n",
    "        \"Rosemary Focaccia\", \"Anchovy Spread\", \"Gorgonzola Cheese\", \n",
    "        \"Speck\", \"Fig Jam\", \"Lemon Olive Oil\"\n",
    "    ],\n",
    "    \"Category\": [\n",
    "        \"Piadina\", \"Piadina\", \"Piadina\", \"Dessert\", \"Salad\", \"Bread\", \n",
    "        \"Condiment\", \"Cheese\", \"Meat\", \"Condiment\", \"Piadina\", \"Piadina\", \n",
    "        \"Piadina\", \"Salad\", \"Bread\", \"Condiment\", \"Cheese\", \"Meat\", \n",
    "        \"Condiment\", \"Condiment\", \"Piadina\", \"Vegetable\", \"Piadina\", \n",
    "        \"Salad\", \"Bread\", \"Condiment\", \"Cheese\", \"Meat\", \"Condiment\", \n",
    "        \"Condiment\"\n",
    "    ],\n",
    "    \"Price\": [\n",
    "        5.50, 6.00, 6.50, 4.00, 7.00, 3.50, 4.50, 8.00, 9.00, 6.00, \n",
    "        7.50, 6.75, 6.25, 8.50, 3.75, 5.25, 7.75, 8.50, 4.75, 5.50, \n",
    "        7.00, 4.25, 9.50, 7.25, 4.00, 5.75, 8.25, 9.25, 6.50, 5.00\n",
    "    ],\n",
    "    \"Stock\": [\n",
    "        20, 15, 25, 10, 12, 30, 40, 18, 22, 25, 14, 16, 20, 10, 35, \n",
    "        28, 15, 12, 30, 25, 18, 22, 14, 10, 40, 20, 15, 12, 18, 25\n",
    "    ],\n",
    "    \"Allergens\": [\n",
    "        \"Gluten, Dairy\", \"Gluten, Dairy\", \"Gluten, Dairy, Pork\", \n",
    "        \"Gluten, Dairy, Nuts\", \"Dairy\", \"Gluten\", \"None\", \"Dairy\", \n",
    "        \"Pork\", \"None\", \"Gluten, Dairy, Truffle\", \"Gluten, Dairy, Pork\", \n",
    "        \"Gluten\", \"Dairy, Eggs\", \"Gluten\", \"None\", \"Dairy\", \"Pork\", \n",
    "        \"Nuts\", \"None\", \"Gluten, Dairy\", \"None\", \"Gluten, Dairy, Fish\", \n",
    "        \"Fish, Eggs\", \"Gluten\", \"Fish\", \"Dairy\", \"Pork\", \"None\", \"None\"\n",
    "    ],\n",
    "    \"Description\": [\n",
    "        \"Traditional Italian flatbread filled with prosciutto and cheese.\",\n",
    "        \"Flatbread filled with grilled vegetables and mozzarella.\",\n",
    "        \"Flatbread filled with ham and melted cheese.\",\n",
    "        \"Sweet flatbread filled with Nutella and crushed hazelnuts.\",\n",
    "        \"Fresh salad with mozzarella, tomatoes, and basil.\",\n",
    "        \"Soft round bread, perfect for pairing with spreads or cured meats.\",\n",
    "        \"Rich and tangy sun-dried tomatoes, ideal for salads or toppings.\",\n",
    "        \"Aged Parmesan cheese, perfect for grating over dishes.\",\n",
    "        \"Thinly sliced cured ham, a classic Italian delicacy.\",\n",
    "        \"Authentic balsamic vinegar from Modena, great for salads and marinades.\",\n",
    "        \"Flatbread filled with truffle cream and cheese.\",\n",
    "        \"Flatbread filled with spicy salami and mozzarella.\",\n",
    "        \"Flatbread filled with vegan cheese and grilled vegetables.\",\n",
    "        \"Crisp romaine lettuce with grilled chicken and Caesar dressing.\",\n",
    "        \"Toasted bread with garlic and olive oil.\",\n",
    "        \"Savory olive spread, perfect for appetizers.\",\n",
    "        \"Creamy ricotta cheese, ideal for desserts or pasta.\",\n",
    "        \"Thinly sliced mortadella, a flavorful Italian sausage.\",\n",
    "        \"Fresh basil pesto sauce, great for pasta or sandwiches.\",\n",
    "        \"Marinated artichokes, perfect for antipasti platters.\",\n",
    "        \"Flatbread filled with a blend of four Italian cheeses.\",\n",
    "        \"Grilled eggplant slices, seasoned with olive oil and herbs.\",\n",
    "        \"Flatbread filled with smoked salmon and cream cheese.\",\n",
    "        \"Fresh tuna salad with celery and mayonnaise.\",\n",
    "        \"Soft focaccia bread infused with rosemary.\",\n",
    "        \"Savory anchovy spread, ideal for bruschetta.\",\n",
    "        \"Creamy Gorgonzola cheese, perfect for sauces or salads.\",\n",
    "        \"Smoky cured speck, a northern Italian specialty.\",\n",
    "        \"Sweet fig jam, great for pairing with cheese.\",\n",
    "        \"Lemon-infused olive oil, perfect for dressings or marinades.\"\n",
    "    ],\n",
    "    \"Calories\": [\n",
    "        350, 300, 400, 450, 250, 200, 50, 110, 150, 20, 380, 420, 310, \n",
    "        270, 180, 90, 120, 160, 80, 70, 400, 60, 450, 320, 220, 40, \n",
    "        130, 170, 100, 30\n",
    "    ],\n",
    "    \"Vegetarian\": [\n",
    "        False, True, False, False, True, True, True, True, False, True, \n",
    "        True, False, True, False, True, True, True, False, True, True, \n",
    "        True, True, False, False, True, False, True, False, True, True\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Supplier data\n",
    "# ----------------------------\n",
    "suppliers = {\n",
    "    \"Supplier ID\": [f\"S{str(i).zfill(3)}\" for i in range(1, 11)],\n",
    "    \"Supplier Name\": [\n",
    "        \"PiadaMaster Inc.\", \"Verde Farms\", \"Dolce Italia\", \n",
    "        \"Formaggi & Co.\", \"Salumi Rossi\", \"Mediterraneo Ltd.\", \n",
    "        \"Truffle Treasures\", \"Balsamico Tradizionale\", \n",
    "        \"Pane Fresco\", \"Olio di Sole\"\n",
    "    ],\n",
    "    \"Contact Email\": [\n",
    "        \"contact@piadamaster.com\", \"info@verdefarms.com\", \n",
    "        \"orders@dolceitalia.it\", \"sales@formaggico.com\", \n",
    "        \"hello@salumirossi.it\", \"support@mediterraneo.com\", \n",
    "        \"info@truffletreasures.com\", \"shop@balsamicotradizionale.it\", \n",
    "        \"contact@panefresco.com\", \"service@oliodisole.it\"\n",
    "    ],\n",
    "    \"Country\": [\n",
    "        \"Italy\", \"Italy\", \"Italy\", \"Italy\", \"Italy\", \n",
    "        \"Greece\", \"Italy\", \"Italy\", \"Italy\", \"Spain\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Create DataFrames\n",
    "# ----------------------------\n",
    "products_df = pd.DataFrame(data)\n",
    "suppliers_df = pd.DataFrame(suppliers)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Assign a random Supplier ID to each product\n",
    "# ----------------------------\n",
    "supplier_ids = suppliers_df[\"Supplier ID\"].tolist()\n",
    "products_df[\"Supplier ID\"] = [random.choice(supplier_ids) for _ in range(len(products_df))]\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Save to SQLite\n",
    "# ----------------------------\n",
    "conn = sqlite3.connect(\"piadineria.db\")\n",
    "\n",
    "products_df.to_sql(\"products\", conn, if_exists=\"replace\", index=False)\n",
    "suppliers_df.to_sql(\"suppliers\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDatabaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x00000256933169F0>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x00000256933169F0>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x00000256933169F0>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x00000256933169F0>, llm=AzureChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025692CF7830>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025692D1DE50>, root_client=<openai.lib.azure.AzureOpenAI object at 0x000002568E0F1850>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x0000025692CF7950>, model_kwargs={}, openai_api_key=SecretStr('**********'), disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://aoai-test-vaalt.openai.azure.com/', deployment_name='gpt-4o', openai_api_version='2024-05-01-preview', openai_api_type='azure'), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=AzureChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025692CF7830>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025692D1DE50>, root_client=<openai.lib.azure.AzureOpenAI object at 0x000002568E0F1850>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x0000025692CF7950>, model_kwargs={}, openai_api_key=SecretStr('**********'), disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://aoai-test-vaalt.openai.azure.com/', deployment_name='gpt-4o', openai_api_version='2024-05-01-preview', openai_api_type='azure'), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"sqlite:///piadineria.db\")\n",
    "\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "\n",
    "sql_toolkit = SQLDatabaseToolkit(db=db, llm=model)\n",
    "sql_toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to cart tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool to add an item to the cart\n",
    "@tool\n",
    "def add_to_cart(item_name: str, item_price: float) -> str:\n",
    "    \"\"\"Add an item to the cart.\"\"\"\n",
    "    url = 'http://localhost:3000/cart'  # Ensure this matches the JSON Server endpoint\n",
    "    cart_item = {\n",
    "        'name': item_name,\n",
    "        'price': item_price\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=cart_item)\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "        return f\"Item '{item_name}' added to cart successfully.\"\n",
    "    else:\n",
    "        return f\"Failed to add item to cart: {response.status_code} {response.text}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import time\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "\n",
    "file_path = (\n",
    "    \"documents\"\n",
    ")\n",
    "loader = PyPDFDirectoryLoader(file_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import AzureAISearchRetriever\n",
    "vector_store.add_documents(documents=docs)\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "rag_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"document_search\",\n",
    "    \"\"\"\n",
    "    Search and return information restaurants health certificate and owner's history.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"You are an AI assistant for a Piadineria Restaurant. \n",
    "            You help customers explore the menu and choose the best piadine or Italian specialties through friendly, interactive questions.\n",
    "            When the user asks for product details (ingredients, allergens, vegetarian options, price, etc.), you can query the product database.\n",
    "\n",
    "            Once the user is ready to order, ask if they'd like to add the selected item to their cart.\n",
    "            If they confirm, add the item to the cart using your tools.\n",
    "\n",
    "            When using a tool, respond only with the final result. For example:\n",
    "            Human: Add Classic Piadina to the cart with price 5.50\n",
    "            AI: Item 'Classic Piadina' added to cart successfully.\n",
    "        \"\"\"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "load_dotenv()\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"askmamma\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "from langsmith import Client\n",
    "\n",
    "client = Client(\n",
    "  api_key=os.getenv(\"LANGSMITH_API_KEY\"),  # This can be retrieved from a secrets manager\n",
    "  api_url=os.getenv(\"LANGSMITH_ENDPOINT\"),  # Update appropriately for self-hosted installations or the EU region\n",
    ")\n",
    "\n",
    "tracer = LangChainTracer(client=client, project_name=\"askmamma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello! Welcome to our Piadineria Restaurant. How can I assist you today? Are you looking to explore our menu or do you have any specific questions?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "User: hi\n",
      "AI: Hello! Welcome to our Piadineria Restaurant. How can I assist you today? Are you looking to explore our menu or do you have any specific questions?\n"
     ]
    }
   ],
   "source": [
    "# Setup the toolkit\n",
    "toolkit = [rag_tool, add_to_cart, sql_toolkit.get_tools()[0], sql_toolkit.get_tools()[1], sql_toolkit.get_tools()[2], sql_toolkit.get_tools()[3]]\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    " \n",
    "message_history = ChatMessageHistory()\n",
    "\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = create_openai_tools_agent(model, toolkit, prompt)\n",
    "\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=toolkit, verbose=True)\n",
    "\n",
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    # This is needed because in most real world scenarios, a session id is needed\n",
    "    # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "    lambda session_id: message_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    " \n",
    "\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    user_input = input(\"Type your question here (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "    result = agent_with_chat_history.invoke(\n",
    "        {\"input\": user_input},\n",
    "        # This is needed because in most real world scenarios, a session id is needed\n",
    "        # It isn't really used here because we are using a simple in memory ChatMessageHistory\n",
    "        config={\"configurable\": {\"session_id\": \"<foo>\"}, \"callbacks\": [tracer]},\n",
    "    )\n",
    "    print(f'User: {user_input}')\n",
    "    print(f'AI: {result['output']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent output evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"QA Example Dataset\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "client.create_examples(\n",
    "    dataset_id=dataset.id,\n",
    "    examples=[\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"What are the ingredients in the Classic Piadina?\"},\n",
    "            \"outputs\": {\"answer\": \"Traditional Italian flatbread filled with prosciutto and cheese.\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"Is the Vegetarian Piadina gluten-free?\"},\n",
    "            \"outputs\": {\"answer\": \"No, it contains gluten and dairy\"},\n",
    "        },\n",
    "        {\n",
    "            \"inputs\": {\"question\": \"Add Classic Piadina to the cart with price 5.50.\"},\n",
    "            \"outputs\": {\"answer\": \"Item 'Classic Piadina' added to cart successfully.\"},\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent tool evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from langsmith import testing as t\n",
    "\n",
    "@pytest.mark.langsmith\n",
    "def test_searches_for_correct_ticker() -> None:\n",
    "  \"\"\"Test that the model looks up the correct ticker on simple query.\"\"\"\n",
    "  # Log the test example\n",
    "  query = \"What is the price of Apple?\"\n",
    "  t.log_inputs({\"query\": query})\n",
    "  expected = \"AAPL\"\n",
    "  t.log_reference_outputs({\"ticker\": expected})\n",
    "\n",
    "  # Call the agent's model node directly instead of running the full ReACT loop.\n",
    "  result = agent.nodes[\"agent\"].invoke(\n",
    "      {\"messages\": [{\"role\": \"user\", \"content\": query}]}\n",
    "  )\n",
    "  tool_calls = result[\"messages\"][0].tool_calls\n",
    "  if tool_calls[0][\"name\"] == polygon_aggregates.name:\n",
    "      actual = tool_calls[0][\"args\"][\"ticker\"]\n",
    "  else:\n",
    "      actual = None\n",
    "  t.log_outputs({\"ticker\": actual})\n",
    "\n",
    "  # Check that the right ticker was queried\n",
    "  assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
